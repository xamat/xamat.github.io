<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.70)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>The NeXT MusicKit </TITLE>
<META NAME="description" CONTENT="The NeXT MusicKit ">
<META NAME="keywords" CONTENT="Thesis_forHTML">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="Thesis_forHTML.css">

<LINK REL="next" HREF="node73.html">
<LINK REL="previous" HREF="node71.html">
<LINK REL="up" HREF="node71.html">
<LINK REL="next" HREF="node73.html">
</HEAD>

<BODY >

<DIV CLASS="navigation"><!--Navigation Panel-->
<A NAME="tex2html1179"
  HREF="node73.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="next.png"></A> 
<A NAME="tex2html1177"
  HREF="node71.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="up.png"></A> 
<A NAME="tex2html1171"
  HREF="node71.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="prev.png"></A>   
<BR>
<B> Next:</B> <A NAME="tex2html1180"
  HREF="node73.html">MODE and Siren</A>
<B> Up:</B> <A NAME="tex2html1178"
  HREF="node71.html">Music Processing Frameworks</A>
<B> Previous:</B> <A NAME="tex2html1172"
  HREF="node71.html">Music Processing Frameworks</A>
<BR>
<BR></DIV>
<!--End of Navigation Panel-->

<H2><A NAME="SECTION00341000000000000000"></A><A NAME="sub:NeXT-Music-Kit"></A>
<BR>
The NeXT MusicKit 
</H2>

<P>
The MusicKit is an object-oriented software system for building music,
sound, signal processing, and MIDI applications. It has been used
in such diverse commercial applications as music sequencers, computer
games, and document processors. The MusicKit was the first to unify
the MIDI and Music V paradigms.

<P>
The NeXt Music Kit was the musical framework of the Next environment
and it was the musical counterpart of the Sound Kit just presented
in section <A HREF="node70.html#sub:NeXT-Sound-Kit">2.3.3</A>. But unlike the Sound Kit the
Music Kit is still maintained and available for different platforms
(see [<A
 HREF="node207.html#www-MusicKit">www-MusicKit, </A>]).

<P>
The NeXT MusicKit was first demonstrated at the 1988 NeXT product
introduction and was bundled in NeXT software releases 1.0 and 2.0.
Beginning with NeXT's 3.0 release, the MusicKit was no longer part
of the standard NeXT software release but was supported and distributed
as Version 4.0 by the Center for Computer Research in Music and Acoustics
(CCRMA) of Stanford University. Versions 5.0 to 5.4.1 were then supported
by tomandandy music, porting to several more popular operating systems.
Currently source code is Freely available for everything, with the
exception of the NeXT hardware implementation of the low-level sound
and DSP drivers (see [<A
 HREF="node207.html#www-MusicKit">www-MusicKit, </A>]). 

<P>
Some of the most important features in MusicKit are, according to
its original author (see [<A
 HREF="node207.html#www-JaffeMusicKit">www-JaffeMusicKit, </A>]):

<P>

<UL>
<LI>Useful for composers writing real-time computer music applications.
</LI>
<LI>Also useful for programmers writing cross-platform audio/music applications.
</LI>
<LI>Extensible, high-level object-oriented framework that is a super-set
of Music V and MIDI paradigms.
</LI>
<LI>Written in Objective C and C, using Apple's OpenStep/Cocoa API, the
FoundationKit.
</LI>
<LI>Representation system capable of depicting phrase-level structure
such as legato transitions.
</LI>
<LI>General time management/scheduling mechanism, supporting synchronization
to MIDI time code.
</LI>
<LI>Efficient real-time synthesis and sound processing, including option
for quadraphonic sound.
</LI>
<LI>Complete support for multiple MIDI inputs and outputs.
</LI>
<LI>Fully-dynamic DSP resource allocation system with dynamic linking
and loading, on multiple DSPs.
</LI>
<LI>Digital sound I/O from the DSP port with support for serial portdevices
by all popular vendors.
</LI>
<LI>Non-real time mode, where the DSP returns data to the application
or writes a sound file.
</LI>
<LI>Suite of applications, including Ensemble an interactive algorithmic
composition and performance environment (including a built-in sampler),
and ScorePlayer a Scorefile and standard MIDI file player.
</LI>
<LI>Library of instruments, including FM, wavetable, physical modeling
and waveshaping synthesis.
</LI>
<LI>Library of unit generators for synthesis and sound processing.
</LI>
<LI>Documentation, programming examples, utilities, including a soundfile
mixer, sample rate converter, etc.
</LI>
<LI>ScoreFile, a textual scripting language for music.
</LI>
<LI>Connectable audio processing modules or plugins including standard
audio effects such as reverb.
</LI>
<LI>MP3 and Ogg/Vorbis streaming of audio output to web servers using
the libshout library. 
</LI>
</UL>
The Music Kit has tools that address three areas: music representation,
performance and synthesis. The goal is to combine the interactive
gestural control of MIDI [<A
 HREF="node207.html#MIDISpecification">MMA, 1998</A>] with the precise
timbral control of Music V (see <A HREF="node81.html#sub:Music-N-Languages">2.6.1</A>). The
Music Kit fully accepts MIDI data in any form but is not limited by
its specification (for example it has much more resolution in frequency
and amplitude).

<P>
In its first versions the Music Kit generated sounds by sending synthesis
instructions to the NeXT DSP. In its current form the hardware synthesis
has been substituted by software based algorithms. But because of
its architecture the Music Kit can implement virtually any synthesis
strategy.

<P>
In the NeXT Music Kit music is represented in a three-level hierarchy
of <TT>Score</TT>, <TT>Part</TT> and <TT>Note</TT> objects. A <TT>Score</TT>
represents a musical composition, a <TT>Part</TT> corresponds to a
particular means of realization. <TT>Parts</TT> are time-sorted collections
of <TT>Notes</TT>, each of which contains data that described a musical
event. There are methods for rapid insertion, deletion, and lookup
of <TT>Notes</TT>.

<P>
A <TT>Note</TT> consists of a list of attribute-value pairs called
<TT>parameters</TT>, a <TT>NoteType</TT><SPAN  CLASS="textit">,</SPAN> a <TT>NoteTag</TT>
and a <TT>TimeTag</TT>.

<P>
A <TT>Parameter</TT> supplies a value for a particular attribute of
a note such as the frequency or amplitude. A parameter value may be
simple (integer, real or string) or it may be another object. The
<TT>Note</TT> provides methods for setting the value of a parameter
as an <SPAN  CLASS="textit">Envelope</SPAN> or a <SPAN  CLASS="textit">Wavetable</SPAN> object. The way a parameter
is interpreted depended on the <TT>Instrument</TT> that realized the
<TT>Note</TT>. The <TT>Instrument</TT> class defines the protocol
for all objects that realized <TT>Notes</TT>. In some way, parameters
are similar to object-oriented messages, the meaning depends on the
way the method is implemented in the receiving object.

<P>
The <TT>noteType</TT> and <TT>noteTag</TT> are used together to help
interpret a <TT>Note</TT>'s parameters. There are five <TT>noteTypes</TT>:
<TT>NoteDur</TT> represents a note with a duration, <TT>NoteOn</TT>
establishes the beginning of a note, <TT>NoteOff</TT> establishes
the end, <TT>NoteUpdate</TT> represents the middle of the note and
<TT>Mute</TT> is general-purpose. A <TT>noteTag</TT> is an arbitrary
integer used to identify different <TT>Notes</TT> as parts of a musical
phrase or note. (A legato can be created by sending a series of <TT>NoteOns</TT>,
all with the same <TT>noteTag</TT>). This way the Music Kit solves
many of MIDI's problems.

<P>
A <TT>Note</TT>'s <TT>timeTag</TT>, expressed in beats from the beginning
of the performance, specifies when the <TT>Note</TT> is to be performed.

<P>
A entire score can be stored in a score file. Score files are in ASCII
format and can contain any information that is in a Note. Apart, the
Music Kit provides a language called ScoreFile that can be used to
add simple programming constructs such as variables, assignments or
arithmetic expressions. A score may also be stored in a midifile and
utilities are provided for converting to and from standard MIDI file
format.

<P>
During a Music Kit performance, <TT>Note</TT> objects are dispatched
in time-sorted order to objects that realizes them in some matter.
This process involves instances of the classes <TT>Performer</TT>,
<TT>Instrument</TT> and <TT>Conductor</TT>. A <TT>Performer</TT> acquires
<TT>Notes</TT> either from a file, a <TT>Score</TT> or generating
them itself and sent them to one or more instrument. An <TT>Instrument</TT>
receives <TT>Notes</TT> sent to it by one or more <TT>Performers</TT>
and realizes them in some distinct manner. The <TT>Conductor</TT>
acts as a scheduler ensuring that <TT>Notes</TT> are transmitted from
<TT>Performers</TT> to <TT>Instruments</TT> in time-sorted order at
the right time. Both <TT>Performer</TT> and <TT>Instrument</TT> are
abstract superclasses and the Music Kit offers subclasses such as
<TT>SynthInstrument</TT>, <TT>MidiOut</TT> or <TT>ScoreRecorder</TT>.

<P>
In order to generate sound from musical data the Music Kit uses three
main classes: <TT>SynthElement</TT>, <TT>SynthPatch</TT> and <TT>SynthInstrument</TT>.
<TT>SynthElements</TT> are the basic building blocks and they correspond
either to code, through the <TT>UnitGenerator</TT> subclass, or to
data, through the <TT>SynthData</TT> subclass. A <TT>SynthPatch</TT>
is the configuration of <TT>SynthElements</TT> that define a synthesis
strategy and it is analogous to a voice or instrument setting in a
regular synthesizer. Finally the <TT>SynthInstrument</TT> is a subclass
of Instrument that realizes Notes by assigning them to particular
<TT>SynthPatches</TT>.

<P>

<DIV CLASS="navigation"><HR>
<!--Navigation Panel-->
<A NAME="tex2html1179"
  HREF="node73.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="next.png"></A> 
<A NAME="tex2html1177"
  HREF="node71.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="up.png"></A> 
<A NAME="tex2html1171"
  HREF="node71.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="prev.png"></A>   
<BR>
<B> Next:</B> <A NAME="tex2html1180"
  HREF="node73.html">MODE and Siren</A>
<B> Up:</B> <A NAME="tex2html1178"
  HREF="node71.html">Music Processing Frameworks</A>
<B> Previous:</B> <A NAME="tex2html1172"
  HREF="node71.html">Music Processing Frameworks</A></DIV>
<!--End of Navigation Panel-->
<ADDRESS>

2004-10-18
</ADDRESS>
</BODY>
</HTML>
