<html>

<head>
<title>Xavier Amatriain</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<meta name="keywords" content="xavier, amatriain, metrix, clam, c++, maijalas, music, signal, programming">
<meta name="description" content="Xavier Amatriain's Home Page">
<meta name="title" content="Xavier Amatriain's Publications">
<link rel="stylesheet" type="text/css" href="../styles.css">
</head>

<body id="body" onload="parent.pageManager('page_is_loaded','','400px')">
<br>
<p class="main" align="center">
     <a href="index_publications.html">Back to publications</a>
</p>
<br>

<p class="main">
<a class="bold">Authors: Herrera, P. Amatriain, X. Battle, E. Serra, X. (2002)</a> </br>
<a class="bold">Title:</a>"Toward Instrument Segmentation for Music Content Description: a Critical Review of Instrument Classification Techniques" </br>
<a class="bold">In:</a> Proceedings of 1st International Symposium on Music Information Retrieval. Plymouth, MA, USA. </br>
<a class="bold">Year:</a></br>
<a class="bold">Abstract:</a> </br>
<div class="abstract">
A system capable of describing the musical content of any kind of sound file or sound stream, as it is
supposed to be done in MPEG7-compliant applications, should provide an account of the different
moments where a certain instrument can be listened to. In this paper we concentrate on reviewing the
different techniques that have been so far proposed for automatic classification of musical instruments. As
most of the techniques to be discussed are usable only in "solo" performances we will evaluate their
applicability to the more complex case of describing sound mixes. We conclude this survey discussing the
necessity of developing new strategies for classifying sound mixes without a priori separation of sound
sources.
</div>
<div align="center"><a href="ismir2000-herrera.pdf">download pdf</a></div><br>
</p>
</body>

</html>
