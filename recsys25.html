<!DOCTYPE html>
<html>
  <head>
    <title>Xavi's Recsys 2025 Keynote</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="favicon.ico">

    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/starter-template.css" rel="stylesheet">

    <!-- Custom styles from my old webpage -->

	<link rel="stylesheet" type="text/css" href="css/styles.css">
	<link rel="stylesheet" href="css/content-feed.css" media="all">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
	 <div class="container">
	 <h1>Recsys 2025 keynote by Xavier Amatriain</h1>
	<br>
	<br>
	<br>
		 <img src="recsys25.png" title="recsys25" id="recsys_photo" height="200 px"/>
	<iframe id="chatbot" src="https://amatria.in/Xavibot/" style="position: fixed; bottom: 20px; right: 20px; border: 2px solid; width: 285px; height: 500px; z-index: 1000;"></iframe>
<button id="closeChatbot" aria-label="Close chatbot">X</button>
	<h2>Slides</h2>
	Coming soon
  	<h2>References</h2>
  <ul>
    <li><a href="https://dl.acm.org/doi/abs/10.1145/2827872">The perceptron: A probabilistic model for information storage and organization in the brain.</a>< (1957)</li>
    <li><a href="https://en.wikipedia.org/wiki/Perceptrons_(book)">Perceptrons</a> (1969)</li>
	<li><a href="https://dl.acm.org/doi/abs/10.1145/2827872">The MovieLens Datasets: History and Context</a> (2015)</li>
    <li><a href="https://www.cs.uic.edu/~liub/KDD-cup-2007/proceedings/The-Netflix-Prize-Bennett.pdf">The Netflix Prize</a> (2007)</li>
    <li><a href="https://dl.acm.org/doi/abs/10.1145/1345448.1345465">Lessons from the Netflix prize challenge</a> (2007)</li>
	<li><a href="https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429">Netflix Recommendations: Beyond the 5 stars</a> (2012)</li>
    <li><a href="https://dl.acm.org/doi/abs/10.1145/1864708.1864727">Multiverse recommendation: n-dimensional tensor factorization for context-aware collaborative filtering
</a> (2010)</li>
	<li><a href="https://netflixtechblog.com/distributed-neural-networks-with-gpus-in-the-aws-cloud-ccf71e82056b">Distributed Neural Networks with GPUs in the AWS Cloud</a> (2014)</li>
    <li><a href="https://dl.acm.org/doi/abs/10.1145/2645710.2645775">The Recommender Problem Revisited</a> (2014)</li>
	<li><a href="https://dl.acm.org/doi/abs/10.1145/1076034.1076056">Scalable collaborative filtering using cluster-based smoothing</a> (2005)</li>
	<li><a href="https://proceedings.mlr.press/v9/erhan10a.html">Why Does Unsupervised Pre-training Help Deep Learning?</a> (2010)</li>
    <li><a href="https://psycnet.apa.org/record/1959-09865-001">Building high-level features using large scale unsupervised learning</a> (2011)</li>
    <li><a href="https://dl.acm.org/doi/abs/10.1145/2959100.2959190">Deep Neural Networks for YouTube Recommendations</a> (2016)</li>
    <li><a href="https://www.nature.com/articles/nature24270">Mastering the game of Go without human knowledge</a> (2017)</li>
	<li><a href="https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html">Attention is All you Need</a> (2017)</li>
    <li><a href="https://www.gatesnotes.com/search-reader?readerfocus=the-age-of-ai-has-begun">The Age of AI has begun</a> (2023)</li>
    <li><a href="https://arxiv.org/abs/2402.06196">Large Language Models: A Survey</a> (2024)</li>
    <li><a href="https://arxiv.org/abs/2401.14423">Prompt Design and Engineering: Introduction and Advanced Methods</a> (2024)</li>
    <li><a href="https://arxiv.org/abs/2302.07730">Transformer models: an introduction and catalog</a> (2023)</li>
    <li><a href="https://arxiv.org/abs/2305.06474">Do LLMs Understand User Preferences? Evaluating LLMs On User Rating Prediction</a> (2023)</li>	
    <li><a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/20dcab0f14046a5c6b02b61da9f13229-Abstract-Conference.html">Recommender Systems with Generative Retrieval</a> (2023)</li>
	<li><a href="https://research.google/blog/transformers-in-music-recommendation/">Transformers in music recommendation</a> (2024)</li>
    <li><a href="https://arxiv.org/abs/2410.16458">STAR: A Simple Training-free Approach for Recommendations using Large Language Models</a> (2024)</li>
	<li><a href="https://arxiv.org/abs/2504.05522">User Feedback Alignment for LLM-powered Exploration in Large-scale Recommendation Systems</a> (2025)</li>
    <li><a href="https://arxiv.org/abs/2506.08283">Serendipitous Recommendation with Multimodal LLM</a> (2025)</li>
    <li><a href="https://dl.acm.org/doi/full/10.1145/3705328.3748105">Balancing Fine-tuning and RAG: A Hybrid Strategy for Dynamic LLM Recommendation Updates
</a> (2025)</li>
		
  	</ul>
</div>	

  </body>
</html>
